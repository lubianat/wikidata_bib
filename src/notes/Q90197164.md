
Evaluating FAIR maturity through a scalable, automated, community-governed framework
====================================================================================
  
  [@wikidata:Q90197164]  
  
Publication date : 20 of September, 2019  

# Highlights
We propose a scalable, automatable
framework to evaluate digital resources that encompasses measurable indicators, open source tools, and
participation guidelines, which come together to accommodate domain relevant community-defined
FAIR assessments. The components of the framework are: 
(1) Maturity Indicators – community-authored specifications that delimit a specific automatically-measurable FAIR behavior; 
(2) Compliance Tests – small Web apps that test digital resources against individual Maturity Indicators; and 
(3) the Evaluator, a Web application that registers, assembles, and applies community-relevant sets of Compliance Tests against a
digital resource, and provides a detailed report about what a machine “sees” when it visits that resource.

The information in this assessment is designed to guide users to
improve the FAIRness of their digital objects. In our case, the Evaluator has reported failure on 10 Compliance
Tests. Now, we explain how we used the output of these tests to improve the FAIRness of our software.


# Comments

## Tags

# Links
  
 * [Scholia Profile](https://scholia.toolforge.org/work/Q90197164)  
 * [Wikidata](https://www.wikidata.org/wiki/Q90197164)  
 * [Author Disambiguator](https://author-
disambiguator.toolforge.org/work_item_oauth.php?id=Q90197164&batch_id=&match=1&author_list_id=&doit=Get+author+links+for+work)  
 * [DOI](https://doi.org/10.1038/S41597-019-0184-5)  
