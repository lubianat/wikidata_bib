
Crowdsourcing and curation: perspectives from biology and natural language processing
=====================================================================================
  
  [@wikidata:Q28598176]  
  
Publication date : 01 of January, 2016  

# Highlights

# Comments

This paper explores crowdsourcing for biocuration throughseveral case studies that highlight different ways of leveraging ‘the crowd’; these raiseissues about the kind(s) of expertise needed, the motivations of participants, and ques-tions related to feasibility, cost and quality. The paper is an outgrowth of a panel sessionheld at BioCreative V (Seville, September 9–11, 2015)

Task complexity, with Games With A Purpose (GWAPs)and collaborative editing activities at the high end, and micro-taskingenvironments,suchasAmazonMechanical Turk at the lower end of complexity

In n annotation projects that combine linguistic annotation(e.g. annotation of syntactic structure or coreference rela-tions) and domain-specific ‘semantic’ annotation, particu-larly of metadata (e.g. whether or not a pathology reportstates that a tissue sample is pathological), it has long beenrecognized that the different tasks may require very differ-ent  types  of  expertise.

There  is  an  urgent  need  for  an  accurate,  scalable,  cost-effective curation process to overcome the curation bottle-neck.

Conventional  wisdom  suggests  that  biocuration  tasksrequire domain expertise; however, the results of both ex-periments reveal that when the task is structured as care-fully designed micro-tasks, it may be possible to leveragethe  labor  of  the  crowd  to  achieve  rapid  throughput  andcost-effective curation, especially by adding a layer of expert checking.

This event allowed participants to consolidatetheir votes and discuss additional changes. Finally, as anadditional incentive much appreciated by the participants,the same top 20 participants were invited to share author-ship of a publication that describes the verification and theset of curated networks (27). Importantly, the refined net-work model set was made available to the scientific com-munity    through    the    causalbionet    database    (http://causalbionet.com), so that the activity of the scientists whoparticipated in the challenge benefits them and their peer

Throughthese mechanisms, crowdsourcing can become both an edu-cational/training tool and even a recruiting tool, where thebest contributors are engaged on a more regular basis to per-form tasks such as curation.

## Tags

# Links
  
 * [Scholia Profile](https://scholia.toolforge.org/work/Q28598176)  
 * [Wikidata](https://www.wikidata.org/wiki/Q28598176)  
 * [TABernacle](https://tabernacle.toolforge.org/?#/tab/manual/Q28598176/P921%3BP4510)  
 * [Author Disambiguator](https://author-disambiguator.toolforge.org/work_item_oauth.php?id=Q28598176&batch_id=&match=1&author_list_id=&doit=Get+author+links+for+work)  
 * [DOI](https://doi.org/10.1093/DATABASE/BAW115)  
