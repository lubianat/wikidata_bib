
What we talk about when we talk about Wikidata quality: a literature survey
===========================================================================
  
  [@wikidata:Q66776851]  
  
Publication date : 01 of August, 2019  

# Highlights

Our analysis includes 28 papers and categorise by quality dimensions addressed. We showed that a number of quality dimensions has not been yet adequately covered, e.g. accuracy and trustworthiness. Future work should focus on these.

This paper seeks to address
this gap, by providing the following contributions:
• It carries out the first systematic review of literature
about data quality of Wikidata;
• It systematises previous studies according to a common data quality framework;
• It identifies gaps in the existing data quality literature
about Wikidata and suggests future studies accordingly

Yapinus et
al. [63] relied upon the showcase item’s criteria to devise,
in close-collaboration with the community of Wikidata, a
single-grading scale which assigns labels to Items from A (the highest) to E. The grading scale covers the completeness
of an item, described as the number of relevant statements;
the number of the sources used to support the statements;
the labels and descriptions in an appropriate number of languages; links to other wiki projects; and possibly whether
media files are attached.


. Statements must
be verifiable by consulting a referenceable primary source.
This must be accessible ‘by at least some’ Wikidata contributors to confirm the source firsthand 

https://www.wikidata.org/wiki/Wikidata:Verifiability 

The existing literature on data quality is extensive and commonly follows Juran’s[25] definition of quality as “fitness for
use” for its object of study (e.g. [5, 18, 42, 59, 64]).

: (i.) data quality is taskdependent, i.e. the same piece of data may be considered of
sufficient quality for one task, but insufficient for another;
(ii.) it is subjective, whereas a user may find a piece of data
appropriate for a task, another may not deem it suitable for
the same task.

The seminal work of Wang and Strong [59] classifies
eight dimensions into four categories: intrinsic, contextual,
representational, and accessibility. 

Intrinsic Dimensions

Accuracy. Several definitions have been given of accuracy.
For [59] it is the extent to which data is accepted as true and
free of error, whilst [41] defines it as the extent to which the
data value v reflects the correct value v
′
Trustworthiness. It indicates the extent to which the user
deems data as ‘true’ [42] 

Consistency. Finally, [34] argues that “a dataset is consistent if it is free
of conflicting information.” We adopt this definition in the
current work.

Contextual Dimensions

Relevancy. This dimension concerns how useful and important data is for the task at hand [59, 64].

Completeness. [5] includes completeness among the set of
basic data quality dimensions, defining it as the extent to
which a dataset represent a corresponding collection of realworld objects.

Timeliness. According to Zaveri et al. [64], “timeliness measures how up-to-date data is relative to a specific task.”

Representation Dimensions

Ease of understanding. In order to facilitate use, data must
be unambiguous and understandable by its consumers [59].
.

Interoperability. The previous dimension focuses on the representational characteristics of data from the point of view
of human users. Interoperability concerns instead representation under a technical perspective, r

Accessibility Dimensions
Accessibility. Data sources on the web need to be timely
available in order to be integrated with other sources to
produce tailored information for users [36]

Interlinking. On the Linked Data web, datasets need to be
interconnected to enable data integration.

Licence. Therefore, it is important for consumers to provide
datasets with a licence clearly expressing the terms for reuse
and sharing [24].

We aimed to keep in our survey papers which in
their study either:
(1) evaluate one or multiple data quality dimensions of
Wikidata;
(2) develop an approach to identify quality issues tested
on Wikidata.


Accuracy. The number of studies addressing explicitly accuracy on Wikidata is low, compared to other dimensions

Wikidata is the second best performer within the set of knowledge graphs studied

Trustworthiness. 
 Thakkar et al. [56] adopt a data consumer viewpoint, choosing a task—i.e. question answering around a
number of domains—and comparing the quality of Wikidata
and DBpedia over several dimensions.
Although provenancerichness varies in Wikidata, i.e. the extent to which sources
are specified for the piece of data in the graph, this feature—
i.e. references—is simply missing in DBpedia [56].


 In [43] we have devised an approach to evaluate Wikidata external sources,
The results, which include only English language sources, show that Wikidata references are
of good quality overall.
Using the quality criteria set by the
Wikidata community (see Section 2), almost 70% of Wikidata
external references are relevant and around 80% are authoritative.

Brasileiro et al. [11] explore common issues in the Wikidata taxonomy by applying multi-level modelling theory. They highlight three anti-patterns, attributable
to the misuse of P31 and P279. 

Whereas [54] is not a systematic evaluation of any quality
dimension of Wikidata, it reports about the issues encountered by its authors in using Wikidata. Among these issues, a
number of inconsistencies are found in Wikidata taxonomic
structure and in the definitions of some of its properties

The metric
adopted checks only if ranking of statements is allowed in
a knowledge graph. Wikidata is the only one where this
feature is present among the projects evaluated.


Whereas Wikidata outperforms the other knowledge graphs in the evaluation of
schema (i.e. completeness with respect to classes and relations) and population completeness (i.e. referring to all
entities in the graph), its completeness of relations for each
entity in the graph (column completeness) is worse

Wikidata is the
most complete resource when it comes to people, albums
and movies, whilst it trails with respect to organisations,
places, and events. [49] builds a tool to measure Wikidata’s
completeness called COOL-WD10.

--> https://cool-wd.inf.unibz.it/

Ease of understanding. [27] examines the availability of labels
in different languages for seven datasets, including samples
from the LOD cloud, datasets published by museums and
governments, and Wikidata.

Wikidata achieves high scores in each of the metrics gauged.

The number of papers targeting Wikidata’s accuracy was rather low, if we exclude the works developing
automated vandalism detection approaches. This may sound
surprising, considered that accuracy is generally deemed as
a key quality dimension [59]. Future studies should focus
on measuring how accurate Wikidata is, possibly employing existing metrics such as those in [39]

y. The
large size of the Wikidata ontology might be an obstacle to
that [46], hampering the application of automated reasoning approaches (e.g. [40]). A possible solution may be using
dataset slices, similarly to [56]


# Comments

## Tags

# Links
  
 * [Scholia Profile](https://scholia.toolforge.org/work/Q66776851)  
 * [Wikidata](https://www.wikidata.org/wiki/Q66776851)  
 * [Author Disambiguator](https://author-disambiguator.toolforge.org/work_item_oauth.php?id=Q66776851&batch_id=&match=1&author_list_id=&doit=Get+author+links+for+work)  
 * [DOI](https://doi.org/10.1145/3306446.3340822)  
 * [Full text URL](https://opensym.org/wp-content/uploads/2019/08/os19-paper-A17-piscopo.pdf)  
