
Wikidata-lite for Knowledge Extraction and Exploration
======================================================
  
  [@wikidata:Q115216557]  
  
Publication date : 10 of November, 2022  

# Highlights

This paper introduces our preliminary works on Wikidata-lite, a toolkit to build a database offline for knowledge extraction and exploration, e.g., retrieving item information, statements, provenances, or searching entities by their keywords and attributes

Moreover, hosting a local
copy of Wikidata requires powerful servers (minimum hardware requirement: 16 CPU cores, 128GB RAM, and 1.5T SSD
storage [2].)

II. RELATED WORK
Many tools are available to parse, query, and explore knowledge from Wikidata dumps. KGTK is a knowledge graph
toolkit for creating, transforming, merging, and exploring
knowledge graphs [5]. KGTK model knowledge graphs in
tab-separated (TSV) files with four columns: edge-identifier,
head, edge-label, and tail. Wikidata dumps could be converted
to KGTK formats with transformation operations. KGTK
provides many graph manipulation operations such as intersection, subtraction, and joining and other analytics operations
such as calculating node popularities, degrees, shortest paths,
or graph embeddings

WDumper is a toolkit for creating a topical subset (set
of entities related to particular topics and the relationships
between them) from the JSON dump of Wikidata


# Comments

## Tags

# Links
  
 * [Scholia Profile](https://scholia.toolforge.org/work/Q115216557)  
 * [Wikidata](https://www.wikidata.org/wiki/Q115216557)  
 * [Author Disambiguator](https://author-
disambiguator.toolforge.org/work_item_oauth.php?id=Q115216557&batch_id=&match=1&author_list_id=&doit=Get+author+links+for+work)  
 * [DOI](https://doi.org/10.48550/ARXIV.2211.05416)  
 * [Full text URL](https://arxiv.org/pdf/2211.05416.pdf)  
 * [arXiv ID](https://arxiv.org/pdf/2211.05416.pdf)  
