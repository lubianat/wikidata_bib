
Wiki2Prop: A Multimodal Approach for Predicting Wikidata Properties from Wikipedia
==================================================================================
  
  [@wikidata:Q107230303]  
  
Publication date : 19 of April, 2021  

# Highlights
Wikidata is rapidly emerging as a key resource for a multitude ofonline tasks such as Speech Recognition, Entity Linking, QuestionAnswering, or Semantic Search.

Despite the tremendous manual and automatic ef-forts the community invested in the Wikidata project, the growingnumber of entities (now more than 100 million) presents multiplechallenges in terms of knowledge gaps in the graph that are hard totrack.

 In this work, we focus on entities with a dedicatedWikipedia page in any language to make predictions directly basedon textual content. We show that this problem can be formulated asa multi-label classification problem where every property definedin Wikidata is a potential label
 
 Finally, we make Wiki2Prop available as a property recommendersystem that can be activated and used directly in the context of aWikidata entity page
 
 For instance, Queenie (the water-skiing elephant) Wikipediapage1contains at the time of writing no structured information.The distribution of property count among Wikidata entities fol-lows a heavy-tailed distribution, with an average of 3.93 differentproperties per entity; This observation also applies to those entitiesthat have corresponding Wikipedia pages across multiple languageeditions, with a slightly higher average of 4.96 property per entity[12]

One key ingredient of our approach is to considerproperties aslabels, and to model the problem as an instance ofmulti-label learning with incomplete class assignments [5].

We tackle the question of property recommendation in largescale collaborative knowledge base construction. Unlike existingapproaches, our method does not rely on hard-coded rule-setsor heuristics, instead it performs information extraction fromunstructured content related to entities of interest. The proper-ties predicted byWiki2Propcan be used to enrich Wikidata (Seean example of the functionality in Figure 1).

 In [46], a formalevaluation comparing state-of-the-art recommender systems forthis task is provided, including [14], where the authors improvedprevious results by using a tree-based method. However, to the bestof our knowledge,Wiki2Propis the first to use external information(Wikipedia) to enrich Wikidata.

 In [31], meta-information onthe completeness of Wikidata are discussed. The method focuseson evaluating the completeness of entities per property (e.g., areall cantons (states) of Switzerland available through the statement‚Äúcontains administrative territorial entity.‚Äù?). At this point, we wouldalso like to point to two meta-studies that embed this work in abroader context of research conducted on Wikidata. [11] providean overview of the research performed on Wikidata through a sys-tematic study, where the authors identify current research topics aswell as research gaps that require further attention. [29] specificallytackles data quality in Wikidata.

 First, we extract all the prop-erties of each entity of Wikidata that have an EN representationin Wikipedia (more specifically anenwiki sitelink), for a total ofùëõ=7‚Ä≤768‚Ä≤807entities. Then, these pieces of data are filtered usingthe following set of rules:‚Ä¢we extract only distinct properties, regardless of the numberof times they are attached to a single entity.‚Ä¢all Qualifiers and Reference information attached to the state-ments are discarded, as they are not part of our model;‚Ä¢each Property of the typeexternal linksis dismissed, as thoseproperties can generally be efficiently populated by import-ing6from the target database

 We compare the performance ofWiki2Propto a state-of-the-art method used for Wikidata comple-tion, namely Recoin [2], as well as recent contributions in Multi-Label predictions (BPMLL [47] and NNAD[24]). The results showthatWiki2Propperforms significantly better than all the othermethods.

 The resulting model ofWiki2Propis deployed on ToolForge11foreasier integration and querying. In contrast to the model trainedfor our evaluation, our deployed model is trained with the completeavailable datase

 ‚Ä¢Johnny Depp14has an actively maintained page in Wikipedia,and had 32 properties in Wikidata. Wiki2Prop recommendstwo additional propertiesofficial websiteandsibling. The for-mer could be inferred from the classActor, but the propertysiblingis clearly an entity specific information which cannot be predicted through class based statistical analysis.

 Queenie (the waterskiing elephant)This entity has (asof today17) a comparatively short, English only, Wikipediaarticle. Nevertheless,Wiki2Propis able to identify the follow-ing relevant properties:country of origin,imageand furtherstill provides specific properties from the TV show domainas mentioned in the article:original language of film or TVshow,genreandpublication date.

  strongeffect can be seen on protein drawings boosting the properties inthe same context. Further could we discover a correlation betweenblack and white pictures of people and the prediction of the prop-ertydate of death. Finally we observed that pictures of buildingsand places significantly boost the propertycoordinate location.

  Another promising avenue of future work would be to use ourmodel in combination with information extraction methods; thatis, our extended model could also generate candidate values inaddition to predicting which entities and properties to focus on.
# Comments

Super cool
## Tags

# Links
  
 * [Scholia Profile](https://scholia.toolforge.org/work/Q107230303)  
 * [Wikidata](https://www.wikidata.org/wiki/Q107230303)  
 * [TABernacle](https://tabernacle.toolforge.org/?#/tab/manual/Q107230303/P921%3BP4510)  
 * [Author Disambiguator](https://author-disambiguator.toolforge.org/work_item_oauth.php?id=Q107230303&batch_id=&match=1&author_list_id=&doit=Get+author+links+for+work)  
 * [DOI](https://doi.org/10.1145/3442381.3450082)  
