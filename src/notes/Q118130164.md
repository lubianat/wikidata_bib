
Wikidata: The Making Of
=======================
  
  [@wikidata:Q118130164]  
  
Publication date : 30 of April, 2023  

# Highlights

m. Seven years earlier still, in 2005,
it was merely a rough idea of a few PhD students, a conceptual
nucleus that had yet to pick up many important infuences from
others to turn into what is now called Wikidata 

For many practitioners and researchers, Wikidata [68] simply is the
largest freely available knowledge graph today. Indeed, with more
than 1.4 billion statements about over 100 million concepts across
all domains of human knowledge,1 it is a valuable resource in many
applications

Figure 1: Apps using Wikidata (from upper left): Wikipedia
iOS app, mobile search on e/OS/, in-fight app by Eurowings/Lufthansa Systems, Siri (historical glitch exposing
Wikidata IDs), and WikiShootMe tool for Wikipedia editors


Overall, we hope that our work can provide relevant insights not
just about Wikidata, but also about the history of three infuential
ideals that have found their expression in many social, political,
and technological developments of our time, especially on the Web:
(1) Community: the confdence that sensible people will work
together to make the world a better place
(2) Sharing: the goal of making knowledge, and digital resources
in general, freely available to every human
(3) Explication: the goal to formally specify information in explicit, unambiguous, and machine-processable ways

Community: all content (data and schema) is directly controlled by an open community, not by the development team
at Wikimedia Deutschland
(2) Sharing: the data is licensed under Creative Commons CC-0,
which imposes no restrictions on usage or distribution
(3) Explication: content is structured according to its own data
model, is exported in the RDF standard, and is open to machine reading/writing through APIs

(4) Multi-linguality: One Wikidata serves all languages; uservisible labels are translated, but underlying concepts and
structures are shared; language-independent IDs are used
(5) Verifability, not truth: Wikidata relies on external sources
for confrmation; statements can come with references; conficting or debated standpoints may co-exist
(6) Integration with Wikimedia: Wikidata is a data backbone for
other Wikimedia projects (linking articles on the same topic
across languages, providing data displayed in Wikipedia
articles, supplying image tags for Wikimedia Commons, etc.)
(7) Identity provider: Wikidata concepts have stable, languageindependent identifers, linked with other resources (catalogs, archives, social networks, etc.) via external identifers


Basic statistics are
summarized in Table 1. Users of Wikidata’s data include technology
organizations (e.g., Google, IBM [19, 44], Quora [74], reddit, Wolfram Alpha [60], Apple, Amazon, OpenAI [53], Twitter [23]) and
cultural and educational institutions (e.g., the Met [35], Smithsonian [62], InternetArchive [47], The Science Museum [15], dblp [55]

The frst idea of what was to become Wikidata was born in early
May 2005. Google was already strong, Skype had revolutionized
(still voice-only) Internet telephony, Facebook was not fully public,
and Twitter did not exist yet. Wikipedia, launched in 2001, was still
not widely known, but its phase of explosive growth had started.7

The result was the early concept of Semantic Wikipedia, a proposal to use annotations in wikitext markup for embedding structured data into Wikipedia articles [28]

Krötzsch and Vrandečić presented the idea at Wikimania on
August 5th, 2005 (see Fig. 2). Certain of the convincing benefts
of their vision, they called for volunteers to implement it – a task
that Vrandečić, when asked, estimated to take about two weeks’
efort. The German company DocCheck stepped up to donate this
efort, leading to the frst implementation of the software Semantic
MediaWiki (SMW) [26, 29].

For several years, editors and operators were occupied with
running Wikipedia in a time of unprecedented growth. Potentially
disruptive software changes were out of the question, and technical work focused on core functionality (UI, account management,
discussion pages, backend performance).

. One of them was Ontoprise, a Karlsruhe-based SME subcontracted by Paul
Allen’s Vulcan Inc. under the leadership of Mark Greaves to adapt
SMW for knowledge acquisition in the ambitious Halo project [18].
To support development and community outreach, Ontoprise hired
a local computer science student, Lydia Pintscher

: Vrandečić was
still arguing to turn the individual Wikipedias semantic in 2009
(in particular to compare the graphs from the diferent language
editions [58, 59, 71]), whereas Möller favored a single Wikidata for
all languages

a rough consensus between some
participants emerged, which would prompt Vrandečić to start writing a proposal for what at frst was called data.wikimedia.org, but
eventually would become Wikidata.
The project proposal draft20 was presented to the community
by Vrandečić at Wikimania 2011 in Haifa, Israel

At that event, Qamarniso Ismailova, an administrator of the Uzbek Wikipedia, and Vrandečić met. They married in August 2012. The Q prefx in QIDs, used as identifers in Wikidata, is the frst letter in her name.

For Richter and Wikimedia Deutschland this was a major step, as
the planned development team would signifcantly enlarge Wikimedia Deutschland, and necessitate a sudden transformation of the
organization, which Richter managed in the years to come 

With the help of Lisa Seitz-Gruwell at the Wikimedia Foundation,
they secured €1.3 Million in funding for the project: half from
the Allen Institute for AI (AI2),22 and a quarter each from Google
and the Gordon and Betty Moore Foundation

Fortuitously, Google announced the Knowledge Graph in May 2012,
which had a lasting positive impact on the interest into Wikidata.
Wikidata launched on October 29, 2012. This initial launch was,
intentionally, very limited. Users could create new identifers for
concepts (QIDs), label them in many languages, and link them to
Wikipedia articles and other Wikimedia pages


One surprisingly contentious aspect was the use of numeric
QIDs. Numeric QIDs are still being questioned today, with proponents arguing that a qualifed name such as dbp:Tokyo is easier to
understand than Q1490. A major infuence for preferring abstract24
QIDs were discussions with Metaweb regarding their experience
with Freebase. Moreover, most other online databases, authority
fles, and ontologies were also preferring abstract IDs. De-coupling
a concept’s name from its ID can increase stability (since IDs do
not change if names do), but studies found that Wikipedia article
titles often are rather stable identifers [20]. More importantly, however, the founders of Wikidata did not want to use an anglo-centric
solution, nor suggest the use of many diferent language-specifc
identifers (such as dbp:東京都) for the same Item

Figure 7: Number of pages on Wikidata: Wikidata reached
100 million entities just in the week before its tenth birthday

In 2016, Google closed down Freebase and helped with the migration of the data to Wikidata [50]. The Wikidata community picked
up the data carefully and slowly, and ensured that the infux of data
would not push beyond their capacity to maintain it.

The newest wave of expansion is the Wikibase Ecosystem, where
groups and organizations outside Wikimedia use the underlying
software that powers Wikidata (called Wikibase36) to run their own
knowledge graphs, which are often highly inter-connected with
Wikidata and other Wikibase instances, as well as other resources
on the Linked Data Web.

Wikifunctions in turn is envisioned as a wiki-based repository of
executable functions, described in community-curated source code.
These functions will in particular be used to access and transform
data in Wikidata, in order to generate views on the data. These
views – tables, graphs, text – can then be integrated into Wikipedia.
This is a return to the goals of the original Phase 3, which would
increase both the incentives to make the data more coherent, and
the visibility and reach of the data as such. This may then lead to
improved correctness and completeness of the data, since only data
that is used is data that is good (a corollary to Linus’s law of “given
enough eyeballs, all bugs are shallow” [54]).



# Comments

## Tags

# Links
  
 * [Scholia Profile](https://scholia.toolforge.org/work/Q118130164)  
 * [Wikidata](https://www.wikidata.org/wiki/Q118130164)  
 * [Author Disambiguator](https://author-disambiguator.toolforge.org/work_item_oauth.php?id=Q118130164&batch_id=&match=1&author_list_id=&doit=Get+author+links+for+work)  
 * [DOI](https://doi.org/10.1145/3543873.3585579)  
