
Seeking a new biology through text mining.
==========================================
  
  [@wikidata:Q42220103]  
  
Publication date : 01 of July, 2008  

# Highlights

Tens of thousands of biomedical journals exist, and the deluge of new articles in the biomedical
sciences is leading to information overload. Hence, there is much interest in text mining, the use
of computational tools to enhance the human ability to parse and understand complex text.


Imagine that a graduate student enters
the U.S. Library of Congress with the goal
of retrieving all texts relevant to protein
glycosylation. Her problem is straightforward, known among text miners as information retrieval (IR). If the student must
not only find the books but also flag the
most important concepts she encounters
in each, she is performing named entity
recognition (NER). Undaunted by her
workload, imagine she decides to identify relations between concepts, such as
“protein BAD binds to protein BAX” (called
information extraction or IE). Then she
takes on additional tasks such as question/answer (QA) and text summarization
(TS). Computational IR, NER, IE, QA, and
TS are all part of text mining and belong
to the larger field of natural language processing (NLP), which itself is a part of artificial intelligence (AI) that aims to recreate
or surpass the computational ability of
the human brain. Although multiple definitions exist, text mining is typically associated with information retrieval, extraction,
and synthesis, with a special emphasis
on gaining new knowledge (Table 1)


the boundary
between NER, IR, and IE is fuzzy


Information Retrieval (IR). t is difficult to benchmark the efficiency
of IR engines, especially their recall,
because the complete set of documents
relevant to almost any search is inherently
ill defined. 


 biology and medicine are unusually rich
in terminology: the collective vocabulary used by biomedicine incorporates
many millions of terms. The exact number is unknown and constantly in flux.
Because this vocabulary is large and
dynamic, new terms emerge rapidly and
erratically. As a result, the same realworld object may have numerous names
(synonyms), whereas distinct objects
can be identified with the same name
(homonyms).


--> 3.2.3. Text mining and Wikidata community curation



 Moving beyond information
retrieval and extraction, some proportion
of published assertions can be repackaged to form “synthetic ideas,” that is,
new compound concepts that are significantly more valuable to the scientific
community than the sum of their original
assertions.
Even with current text-mining capabilities, such synthetic ideas can be
discovered automatically. 

--> 1.1.1. Literature Based Discovery, hidden knowledge and text-mining

A more distant but nonetheless realistic aim of the
field is to trace and map more sophisticated ideas (idea isomorphisms) that
are expressed differently in different scientific fields yet represent identical
problems or their solutions


 it would be relatively easy to write a similar
engine that answers biological questions like “list all molecular interactors
of protein X with property Y.” Such a
question-answer system would surpass abilities of both human experts
and currently available encyclopedias

 Ideally, scientists
should record and share all useful findings, but in reality results sometimes do
not coincide with the “standard ration”
suitable for journal publication. 

-->  1.1.3. Interoperable publication processes: nanopublications

, there are few incentives to populate, annotate, or
revise information stored in databases.
Also, databases have not yet been optimized for discussion, to allow disagreement, or to represent uncertainty

 The semantic web
can be particularly useful in connection
with text mining, as it provides a way to
mark up text with systematic and structured meta-information.


The text-mining community could provide publishers
with a set of tools that would automatically pre-annotate manuscripts before
publication, subject to approval of
authors (Seringhaus and Gerstein, 2007).
This change undoubtedly may be hard
to implement but would benefit science
because the resulting semantic-webenabled articles would be much easier
to use both for information retrieval and
extraction, as well as for the generation
of knowledge


An experienced biologist can readily
spot inconsistencies in a small map of
molecular interactions. The biologist
looks for logical inconsistency across
multiple statements that are each perfectly reasonable when viewed in isolation but that cannot all be true simultaneously

 This approach would not replace
data analysis by biologists but may save
time in refining models (just as a good
spellchecker does not replace a writer
but allows us to produce prose free of
typos faster).


# Comments

Very well written.

## Tags
1.1. The quest for interoperable knowledge


# Links
  
 * [Scholia Profile](https://scholia.toolforge.org/work/Q42220103)  
 * [Wikidata](https://www.wikidata.org/wiki/Q42220103)  
 * [TABernacle](https://tabernacle.toolforge.org/?#/tab/manual/Q42220103/P921%3BP4510)  
