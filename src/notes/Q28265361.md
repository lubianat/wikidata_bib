
Calling International Rescue: knowledge lost in literature and data landslide!
==============================================================================
  
  [@wikidata:Q28265361]  
  
Publication date : 10 of December, 2009  

# Highlights
The knowledge we seek is often fragmentary and disconnected, spread thinly across thousands of databases and millions of articles in thousands of journals. The intellectual energy required to search this array of data-archives, and the time and money this wastes, has led several researchers to challenge the methods by which we traditionally commit newly acquired facts and knowledge to the scientific record.

 We present some of these initiatives here – a whirlwind tour of recent projects to transform scholarly publishing paradigms, culminating in Utopia and the Semantic Biochemical Journal experiment

 Before reading any further, we are going to ask you to download a piece of software. Together, as we journey through this article, we will test the software [a new PDF document reader, called Utopia Documents (UD)] in different scenario. 

 --> http://getutopia.com/ gives a runtime error

 wiss-Prot will soon contain 500000 protein sequences, of which around half have been annotated by a team of curators that has devoted 600 person years to the task over a 23 year period [18] – an incredible human effort. They achieved this by reading thousands of articles and visiting hundreds of other databases, and carefully distilling out Swiss-Prot-relevant facts. 

 The importance of being earnest in our approaches to such problems, in the way we think about our data, in the way we organize our data, and in the way we write about our data, is crucial if we are to make sense of the complexities [32]. Without such approaches, our literature is in danger of giving way to yet more of what Kerr has described as “touchy-feely text and psychobabble” [33].

 llustration of the use of COHSE
GO terms are highlighted in a webpage; clicking on these reveals glossary information from GO; link targets to PubMed abstracts (such as the one here from Current Opinion in Plant Biology [45]) are provided by modifying the preferences to use an appropriate Google search. (http://cohse.cs.manchester.ac.uk/)

The long-term vision of projects like this, and of the OBO Foundry in particular, is that all biomedical research data should ultimately form a single, consistent, machine-accessible whole (see also http://www.bio2rdf.org).

Simplified Molecular Input Line Entry Specification (SMILES) nomenclature

With Project Prospect, the Royal Society of Chemistry (RSC) has played a pioneering role in introducing meaning (semantics) to published content [47] and creating computer-readable chemistry. 

The ChemSpider Journal of Chemistry is another experiment set up to demonstrate the added value that Web technologies can offer in terms of enriching published information.

Example output from the ChemSpider Journal of Chemistry
Marked-up chemical entities include chemical families, chemical names (pale orange highlights), chemical groups (dark green) and reaction types, with links out to Wikipedia where appropriate (e.g. overlaid here as a ‘callout’).

BioLit is a suite of open-source tools designed to integrate open literature with biological databases 

Public Library of Science (PLoS) Neglected Tropical Diseases (NTD)
In another interesting adventure in semantic publishing, Shotton et al. [34] chose an article in PLoS NTD as a target for enrichment

--> Tis is a good one

A rather different slant on the problem of dissemination and re-use of scientific knowledge is offered by the Liquid Publication Project, a European initiative partnered by Springer Verlag [60]. The intention here is for publications to become fluid entities, created in a collaborative and evolutionary fashion over time, in much the same way as open-source software is developed; there are also parallels here with successful social/collaborative annotation models such as Wikipedia.

The Semantic Biochemical Journal (BJ) experiment was a collaborative project involving the BJ editorial staff and the developers of Utopia [73], a software suite that semantically integrates visualization and data-analysis tools with document-reading and document-management utilities

Shotton's project [34] with PLoS NTD was, in some ways, more ambitious in scope. Despite being limited to a single article, the semantic enhancement provided was found to be a labour-intensive exercise. To render their approach more cost-effective, Shotton recognized the need for greater levels of automation, and he pointed to tools like Reflect to help ease manual mark-up burdens.


# Comments

Very nice overview of the early work on that direction
## Tags

--> - 1.1.1. Literature Based Discovery, hidden knowledge and text-mining
--> 1.1.1.2. Hidden knowledge (explicitly)

# Links
  
 * [Scholia Profile](https://scholia.toolforge.org/work/Q28265361)  
 * [Wikidata](https://www.wikidata.org/wiki/Q28265361)  
 * [Author Disambiguator](https://author-disambiguator.toolforge.org/work_item_oauth.php?id=Q28265361&batch_id=&match=1&author_list_id=&doit=Get+author+links+for+work)  
 * [DOI](https://doi.org/10.1042/BJ20091474)  
