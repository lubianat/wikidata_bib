
Wikipedia citations: A comprehensive data set of citations with identifiers extracted from English Wikipedia
============================================================================================================
  
  [@wikidata:Q106570089]  
  
Publication date : 01 of January, 2021  

# Highlights

To close this gap, we release Wikipedia Citations, a comprehensive data set of citations extracted from Wikipedia. We extracted29.3 million citations from 6.1 million English Wikipedia articles as of May 2020, and classified as being books, journal articles, or Web content. We were thus able to extract 4.0 million citations to scholarly publications with known identifiers—including DOI, PMC, PMID, and ISBN—and further equip an extra 261 thousand citations with DOIs from Crossref. 

A reliable source is defined, in turn, as a secondary and published, ideally scholarly, one.3 Despite the community’s best efforts to add all the needed citations, the majority of articles in Wikipedia might still contain unverified claims, in particular lower quality ones (Lewoniewski, Wecel et al., 2017). 

A clear influence of Wikipedia on scientific research has in turn been found (Thompson & Hanley, 2018), despite a general lack of reciprocity in acknowledging it as a source of information from the scientific literature (Jemielniak & Aibar, 2016; Tomaszewski & MacDonald, 2016).

Our goal is to overcome these two challenges and expand upon previous work (Halfaker, Mansurov et al., 2018), by providing a data set of all citations from English Wikipedia, equipped with identifiers and including the code necessary to replicate and improve upon our work. The resulting data set is available on Zenodo (Singh, West, & Colavizza, 2020), while an accompanying repository contains code and further documentation


https://doi.org/10.5281/zenodo.3940692

 Therefore, we mapped all citations to the same uniform template. For this step, we used the wikiciteparser parser.9 This parser is written in Lua and it can be imported into Python using the lupa library.10

 The model that we constructed is a hybrid deep learning pipeline illustrated in Figure 3. The features were represented as follows:

    Citation text: The citation text in Wikicode syntax was fed to a character- level bidirectional LSTM (Schuster & Paliwal, 1997) on the dummy task of predicting whether the citation text is to a book/journal article or other Web content

The total number of distinct identifiers across all Wikipedia, both previously known and newly found, are given in Table 6. Considering that in the Web of Science (WoS) (Birkle, Pendlebury et al., 2020) at the time there were 34,640,325 unique DOIs (version of June 2020; we only consider the typologies of “article,” “review,” “letter,” and “proceedings paper”), Wikipedia is citing a volume of unique DOIs (1,157,571) corresponding to 3.3% of this total. Yet by doing an exact matching between Wikipedia DOIs and WoS DOIs, we can find 710,913 identifiers that are in common, or just 2% of the WoS total. This also entails that approximately 61% of unique DOIs in Wikipedia are indexed in the WoS

We next consider the WoS subject categories for these 710,913 articles.

We publish the Wikipedia Citations data set, consisting of 29.276 million citations extracted from 6.069 million articles from English Wikipedia.


# Comments

## Tags

# Links
  
 * [Scholia Profile](https://scholia.toolforge.org/work/Q106570089)  
 * [Wikidata](https://www.wikidata.org/wiki/Q106570089)  
 * [TABernacle](https://tabernacle.toolforge.org/?#/tab/manual/Q106570089/P921%3BP4510)  
 * [Author Disambiguator](https://author-disambiguator.toolforge.org/work_item_oauth.php?id=Q106570089&batch_id=&match=1&author_list_id=&doit=Get+author+links+for+work)  
 * [DOI](https://doi.org/10.1162/QSS_A_00105)  
