
GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models
==========================================================================================
  
  [@wikidata:Q117229471]  
  
Publication date : 17 of March, 2023  

# Highlights


Our analysis indicates that approximately 19% of jobs have at least
50% of their tasks exposed when considering both current model capabilities and anticipated tools built upon
them. Human assessments suggest that only 3% of U.S. workers have over half of their tasks exposed to
GPT when considering existing language and code capabilities without additional software or modalities.


General-purpose technologies (e.g. printing, the steam engine) (GPTs) are characterized by widespread
proliferation, continuous improvement, and the generation of complementary innovations (Bresnahan and
Trajtenberg, 1995; Lipsey et al., 2005). Their far-reaching consequences, which unfold over decades, are
difficult to anticipate, particularly in relation to labor demand (Bessen, 2018; Korinek and Stiglitz, 2018;
Acemoglu et al., 2020; Benzell et al., 2021).

We present our results based on an exposure rubric, in which we define exposure as a measure of whether
access to a GPT or GPT-powered system would reduce the time required for a human to perform a specific
DWA or complete a task by at least 50 percent. We provide a summary of our rubric below, while the
complete rubric can be found in A.1. When we have labels for DWAs, we first aggregate at the task level
before aggregating at the occupation level.

No exposure (E0) if:
‚Ä¢ there is no or minimal reduction in the time required to complete the activity or task
while maintaining equivalent quality or
‚Ä¢ using any combination of the capabilities described in accordance with the below criteria
would decrease the quality of the activity/task output.
Direct exposure (E1) if:
‚Ä¢ using solely the theoretical LLM or GPT-4 described via ChatGPT or the OpenAI
playground can decrease the time required to complete the DWA or task by at least half
(50%).
LLM+ Exposed (E2) if:
‚Ä¢ access to the LLM alone would not reduce the time required to complete the activity/task
by at least half, but
‚Ä¢ additional software could be developed on to the LLM that could reduce the time it takes
to complete the specific activity/task with quality by at least half. Among these systems,
we count access to image generation systems. a

Recent research indicates that GPT-4 serves as an effective discriminator, capable of applying intricate
taxonomies and responding to changes in wording and emphasis. (OpenAI, 2023b) The outcomes of GPT-4
task classification are sensitive to alterations in the rubric‚Äôs wording, the prompt‚Äôs order and composition, the
presence or absence of specific examples in the rubric, the level of detail provided, and key term definitions.


ks in the dataset as being exposed to GPTs.
Based on the ùõΩ values, we estimate that 80% of workers belong to an occupation with at least one task
exposed to GPTs, while 19% of workers are in an occupation where over half the tasks are labeled as exposed.

Our findings indicate that the importance of science and critical thinking skills are strongly negatively
associated with exposure, suggesting that occupations requiring these skills are less likely to be impacted by
current language models. Conversely, programming and writing skills show a strong positive association
with exposure, implying that occupations involving these skills are more susceptible to being influenced by
language models (see Table 5 for detailed results).

 While our findings suggest that out-of-the-box
these models are relevant to a meaningful share of workers and tasks, they also suggest that the software innovations they spawn could drive a much broader impact.

Widespread adoption of these models, however, necessitates the identification of existing bottlenecks. A
key determinant of their utility is the level of confidence humans place in them, as well as habits. For instance,
in the legal profession, the models‚Äô usefulness hinges upon whether legal professionals can trust their output
without resorting to verifying original documents or conducting independent research. The cost and flexibility
of the technology, worker and firm preferences, and incentives also play a significant role in the adoption of
tools built on top of LLMs

One possibility is that time savings and seamless application will hold greater importance than quality
improvement for the majority of tasks. Another is that the initial focus will be on augmentation, followed by
automation (Huang and Rust, 2018). One way this might take shape is that an augmentation phase where jobs
first become more precarious (writers become freelancers) could play out prior to full automation.



# Comments

## Tags

# Links
  
 * [Scholia Profile](https://scholia.toolforge.org/work/Q117229471)  
 * [Wikidata](https://www.wikidata.org/wiki/Q117229471)  
 * [Author Disambiguator](https://author-disambiguator.toolforge.org/work_item_oauth.php?id=Q117229471&batch_id=&match=1&author_list_id=&doit=Get+author+links+for+work)  
 * [DOI](https://doi.org/10.48550/ARXIV.2303.10130)  
 * [Full text URL](https://arxiv.org/pdf/2303.10130.pdf)  
 * [arXiv ID](https://arxiv.org/pdf/2303.10130.pdf)  
